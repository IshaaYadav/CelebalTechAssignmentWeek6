{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.13.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b6fdc-0589-44dd-8e3c-46bab66defb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1168, 54)\n",
      "Test shape: (292, 54)\n",
      "Training and evaluating RandomForest...\n",
      "RandomForest evaluation complete.\n",
      "Training and evaluating GradientBoosting...\n",
      "GradientBoosting evaluation complete.\n",
      "Training and evaluating XGBoost...\n",
      "XGBoost evaluation complete.\n",
      "Training and evaluating SVR...\n",
      "SVR evaluation complete.\n",
      "Training and evaluating KNN...\n",
      "KNN evaluation complete.\n",
      "Training and evaluating LinearRegression...\n",
      "LinearRegression evaluation complete.\n",
      "Tuning RandomForest...\n",
      "Best params for RandomForest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForest_tuned evaluation complete.\n",
      "Tuning GradientBoosting...\n",
      "Best params for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "GradientBoosting_tuned evaluation complete.\n",
      "Tuning XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ISHA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "XGBoost_tuned evaluation complete.\n",
      "Tuning SVR...\n",
      "Best params for SVR: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVR_tuned evaluation complete.\n",
      "Tuning KNN...\n",
      "Best params for KNN: {'n_neighbors': 7}\n",
      "KNN_tuned evaluation complete.\n",
      "Tuning LinearRegression...\n",
      "Best params for LinearRegression: {}\n",
      "LinearRegression_tuned evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c408494a73cf>:187: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=tuned_results.keys(), y=[v[\"R2 Score\"] for v in tuned_results.values()], palette=\"viridis\", hue=None)\n",
      "<ipython-input-1-c408494a73cf>:198: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=tuned_results.keys(), y=[v[\"RMSE\"] for v in tuned_results.values()], palette=\"coolwarm\", hue=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# model_train.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# SECTION 1: Setup & Load Data\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"visuals\", exist_ok=True)\n",
    "\n",
    "data_path = \"data/processed_train.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "X = df.drop(columns=[\"saleprice\"])\n",
    "y = df[\"saleprice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "# SECTION 2: Define Models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0),\n",
    "    \"SVR\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"LinearRegression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# SECTION 3: Evaluation Function\n",
    "results = {}\n",
    "\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"R2 Score\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae\n",
    "    }\n",
    "\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(residuals, kde=True, bins=30, color='steelblue')\n",
    "    plt.title(f\"Residual Distribution - {name}\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"visuals/residuals_{name}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')\n",
    "    plt.title(f\"Actual vs Predicted - {name}\")\n",
    "    plt.xlabel(\"Actual SalePrice\")\n",
    "    plt.ylabel(\"Predicted SalePrice\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"visuals/actual_vs_predicted_{name}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{name} evaluation complete.\")\n",
    "\n",
    "# SECTION 4: Train Untuned Models\n",
    "for name, model in models.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    evaluate_model(name, model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df = metrics_df.sort_values(by=\"R2 Score\", ascending=False)\n",
    "metrics_df.to_csv(\"results/metrics_summary.csv\")\n",
    "\n",
    "# SECTION 5: Hyperparameter Tuning\n",
    "search_spaces = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [10, 20, None],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        },\n",
    "        \"search\": \"grid\"\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5]\n",
    "        },\n",
    "        \"search\": \"grid\"\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(random_state=42, verbosity=0),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5]\n",
    "        },\n",
    "        \"search\": \"random\"\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        \"model\": SVR(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"gamma\": [\"scale\", \"auto\"],\n",
    "            \"kernel\": [\"rbf\", \"linear\"]\n",
    "        },\n",
    "        \"search\": \"grid\"\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [3, 5, 7, 9]\n",
    "        },\n",
    "        \"search\": \"grid\"\n",
    "    },\n",
    "    \"LinearRegression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {},\n",
    "        \"search\": \"grid\"\n",
    "    }\n",
    "}\n",
    "\n",
    "tuned_results = {}\n",
    "tuned_params = {}\n",
    "\n",
    "for name, config in search_spaces.items():\n",
    "    print(f\"Tuning {name}...\")\n",
    "\n",
    "    if config[\"search\"] == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            cv=5,\n",
    "            scoring=\"r2\",\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "    else:\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=config[\"model\"],\n",
    "            param_distributions=config[\"params\"],\n",
    "            n_iter=10,\n",
    "            cv=5,\n",
    "            scoring=\"r2\",\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    tuned_params[name] = best_params\n",
    "    print(f\"Best params for {name}: {best_params}\")\n",
    "\n",
    "    evaluate_model(f\"{name}_tuned\", best_model, X_train, X_test, y_train, y_test)\n",
    "    tuned_results[name] = results[f\"{name}_tuned\"]\n",
    "\n",
    "pd.DataFrame(tuned_results).T.to_csv(\"results/tuned_metrics_summary.csv\")\n",
    "pd.DataFrame(tuned_params).T.to_csv(\"results/tuning_results.csv\")\n",
    "\n",
    "# SECTION 6: Visualize Summary + Best Model\n",
    "\n",
    "# R2 Score Comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=tuned_results.keys(), y=[v[\"R2 Score\"] for v in tuned_results.values()], palette=\"viridis\", hue=None)\n",
    "plt.title(\"R2 Score Comparison - Tuned Models\")\n",
    "plt.ylabel(\"R2 Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/r2_score_comparison.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# RMSE Comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=tuned_results.keys(), y=[v[\"RMSE\"] for v in tuned_results.values()], palette=\"coolwarm\", hue=None)\n",
    "plt.title(\"RMSE Comparison - Tuned Models\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/rmse_comparison.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Highlight Best Model\n",
    "best_model_name = max(tuned_results, key=lambda k: tuned_results[k][\"R2 Score\"])\n",
    "import shutil\n",
    "shutil.copyfile(\n",
    "    f\"visuals/actual_vs_predicted_{best_model_name}_tuned.png\",\n",
    "    \"visuals/best_model_confusion.png\"\n",
    ")\n",
    "print(f\"Best model is: {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
